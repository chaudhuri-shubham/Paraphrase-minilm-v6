import os
import time
import pandas as pd
from pptx import Presentation
import textract
import pptx2txt2
import warnings
warnings.filterwarnings("ignore")

# ----------------------------- CONFIG ---------------------------------
PPT_FOLDER = "pptx_files"     # Folder containing all pptx files
OUTPUT_EXCEL = "pptx_extraction_comparison.xlsx"
CHECK_READING_ORDER = True    # Toggle reading order check
BASELINE_LIB = "python-pptx"  # Used for accuracy comparison
# ----------------------------------------------------------------------

# ----------------------------- EXTRACTORS ------------------------------

def extract_text_python_pptx(file_path):
    prs = Presentation(file_path)
    text = []
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text.append(shape.text)
            elif shape.has_table:
                for row in shape.table.rows:
                    for cell in row.cells:
                        text.append(cell.text)
    return "\n".join(text)

def extract_text_textract(file_path):
    """Extract text using textract"""
    return textract.process(file_path).decode("utf-8", errors="ignore")

def extract_text_pptx2txt2(file_path):
    """Extract text using pptx2txt2"""
    return pptx2txt2.process(file_path)

# ----------------------------------------------------------------------
# ----------------------------- UTILITIES -------------------------------

def check_reading_order(text):
    """Simple heuristic for reading order detection"""
    if not text or len(text.strip()) < 10:
        return "Insufficient data"
    lines = text.strip().split("\n")
    avg_len = sum(len(l.strip()) for l in lines) / len(lines)
    if avg_len < 10:
        return "Line-wise"
    elif avg_len < 50:
        return "Paragraph-wise"
    else:
        return "Random"

def text_metrics(text):
    """Return text length and word count"""
    if not text:
        return {"length": 0, "word_count": 0}
    words = text.split()
    return {"length": len(text), "word_count": len(words)}

def calculate_accuracy(base_text, compare_text):
    """Approximate text overlap accuracy"""
    if not base_text or not compare_text:
        return 0
    base_words = set(base_text.split())
    comp_words = set(compare_text.split())
    if not base_words:
        return 0
    return round(len(base_words & comp_words) / len(base_words), 3)

def completeness_score(base_text, compare_text):
    """Ratio of extracted words vs baseline words"""
    if not base_text:
        return 0
    base_len = len(base_text.split())
    comp_len = len(compare_text.split())
    return round(min(comp_len / base_len, 1), 3) if base_len > 0 else 0

def noise_ratio(text):
    """Estimate noise ratio based on special chars"""
    if not text:
        return 0
    specials = sum(1 for c in text if not (c.isalnum() or c.isspace()))
    return round(specials / len(text), 3)

def duplicate_rate(text):
    """Estimate duplicate line ratio"""
    if not text:
        return 0
    lines = [l.strip() for l in text.split("\n") if l.strip()]
    if not lines:
        return 0
    unique = len(set(lines))
    return round(1 - (unique / len(lines)), 3)

def quality_score(acc, comp, noise, dup):
    """Weighted quality score"""
    return round((acc * 0.4 + comp * 0.3 + (1 - noise) * 0.2 + (1 - dup) * 0.1), 3)

# ----------------------------------------------------------------------
# ---------------------------- MAIN PROCESS -----------------------------

extractors = {
    "python-pptx": extract_text_python_pptx,
    "textract": extract_text_textract,
    "pptx2txt2": extract_text_pptx2txt2
}

results_summary = []
errors = []
os.makedirs(PPT_FOLDER, exist_ok=True)
ppt_files = [f for f in os.listdir(PPT_FOLDER) if f.endswith(".pptx")]

extracted_texts = {lib: {} for lib in extractors.keys()}

# ------------------------ Extraction Loop ------------------------------
for lib_name, func in extractors.items():
    print(f"Processing with: {lib_name}")
    lib_results = []

    for ppt_file in ppt_files:
        ppt_path = os.path.join(PPT_FOLDER, ppt_file)
        start_time = time.time()

        try:
            text = func(ppt_path)
            time_taken = round(time.time() - start_time, 2)
            extracted_texts[lib_name][ppt_file] = text

            metrics = text_metrics(text)
            order = check_reading_order(text) if CHECK_READING_ORDER else "Skipped"

            lib_results.append({
                "File": ppt_file,
                "Time (s)": time_taken,
                "Text Length": metrics["length"],
                "Word Count": metrics["word_count"],
                "Reading Order": order,
                "Accuracy": None,
                "Completeness": None,
                "Noise Ratio": noise_ratio(text),
                "Duplicate Rate": duplicate_rate(text),
                "Quality Score": None
            })

        except Exception as e:
            errors.append({"Library": lib_name, "File": ppt_file, "Error": str(e)})
            lib_results.append({
                "File": ppt_file,
                "Time (s)": None,
                "Text Length": None,
                "Word Count": None,
                "Reading Order": "Error",
                "Accuracy": None,
                "Completeness": None,
                "Noise Ratio": None,
                "Duplicate Rate": None,
                "Quality Score": None
            })

    results_summary.append((lib_name, pd.DataFrame(lib_results)))

# ----------------------------------------------------------------------
# ----------------------- Compute Accuracy & Quality --------------------

if BASELINE_LIB in extracted_texts:
    base_dict = extracted_texts[BASELINE_LIB]
    for lib_name, df in results_summary:
        if lib_name == BASELINE_LIB:
            for i, row in df.iterrows():
                df.loc[i, "Accuracy"] = 1.0
                df.loc[i, "Completeness"] = 1.0
                df.loc[i, "Quality Score"] = 1.0
            continue

        for i, row in df.iterrows():
            file_name = row["File"]
            base_text = base_dict.get(file_name, "")
            comp_text = extracted_texts[lib_name].get(file_name, "")
            acc = calculate_accuracy(base_text, comp_text)
            comp = completeness_score(base_text, comp_text)
            noise = row["Noise Ratio"]
            dup = row["Duplicate Rate"]
            qscore = quality_score(acc, comp, noise, dup)

            df.loc[i, "Accuracy"] = acc
            df.loc[i, "Completeness"] = comp
            df.loc[i, "Quality Score"] = qscore

# ----------------------------------------------------------------------
# ----------------------- Write to Excel Output -------------------------

with pd.ExcelWriter(OUTPUT_EXCEL, engine="openpyxl") as writer:
    combined_summary_rows = []

    for lib_name, df in results_summary:
        # Metrics sheet
        df.to_excel(writer, sheet_name=f"{lib_name}_Metrics", index=False)

        # Extracted text sheet
        text_data = pd.DataFrame(
            [(file, extracted_texts[lib_name].get(file, "")) for file in ppt_files],
            columns=["File", "Extracted Text"]
        )
        text_data.to_excel(writer, sheet_name=f"{lib_name}_Text", index=False)

        for _, r in df.iterrows():
            combined_summary_rows.append({
                "Library": lib_name,
                **r.to_dict()
            })

    pd.DataFrame(combined_summary_rows).to_excel(writer, sheet_name="Combined_Summary", index=False)
    pd.DataFrame(errors).to_excel(writer, sheet_name="Errors", index=False)

print(f"\nâœ… Extraction completed successfully.\nResults saved to {OUTPUT_EXCEL}")